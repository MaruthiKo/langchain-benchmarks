{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "Let's evaluate your architecture on a Q&A dataset for the LangChain python docs.\n",
    "\n",
    "Common RAG architectures have two main components:\n",
    "1. Retriever -> provides information from a knowledge base. Vector search is simple and powerful, but this can include any database or arbitrary search engine\n",
    "2. Response generator -> synthesizes a response to the user input based on a mixture of learned knowledge and the retrieved input.\n",
    "\n",
    "Focusing on retrievers for unstructured data: you still have some additional design decisions you may want to make:\n",
    "\n",
    "- What chunk size(s) to use for each document: too large and your system will be able to consider fewer documents at a time. Too small and the chunks themselves lack important context needed to interpret their content.\n",
    "- How to index a single chunk: generating a single vector from an embedding model may be fine, or you can generate additional vectors based on summaries, hypothetical questions, or other related content. Some may even consider incorporating a keyword index or other structured metadata to better support different types of searches.\n",
    "- How to assemble the retrieved chunks: once you've fetched the k-best list of \"relevant\" documents, you may want to do things like:\n",
    "  - re-integrate the document into its parent context.\n",
    "  - rerank the documents based on other criteria\n",
    " \n",
    "All of these options come with tradeoffs in cost, response quality, and time. This may seem overwhelming at first! The good news is that the retrieval and response mechanism can be modular -> the better the information, the better the response, and the better the LLM, the better it is able to integrate the knowledge.\n",
    "\n",
    "This notebook provides a RAG gym/playground you can use to evaluate different RAG strategies on a Q&A dataset generated from LangChain's python docs. The intent is to make it easy to experiment with different techniques to see their tradeoffs and make the appropriate decision for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49db759-7ce6-4ab7-a58f-7fc3a6a7c8ec",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "We will install quite a few prerequisites for this example since we are comparing various techinques and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langchain_benchmarks\n",
    "# %pip install -U langchain langsmith langchainhub chromadb openai huggingface pandas langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1631daae-e1ab-4008-84b0-da5937d3b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae13f6-cd40-41e6-bd02-bd683e91cbff",
   "metadata": {},
   "source": [
    "For this code to work, please configure LangSmith environment variables with your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b518cf-99fb-44be-8acb-ee0a8ba62272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\n",
    "    \"LANGCHAIN_ENDPOINT\"\n",
    "] = \"http://localhost:1984\"  # \"https://api.smith.langchain.com\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"sk-...\"  # Your API key\n",
    "\n",
    "# Silence warnings from HuggingFace\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a666d-8bf5-4bfd-8b20-8b7defdb8cd5",
   "metadata": {},
   "source": [
    "## Review Q&A \"environments\"\n",
    "\n",
    "The registry provides configurations to test out common architectures on curated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset\n",
    "from langchain_benchmarks.rag import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3644d211-382e-41aa-b282-21b01d28fc35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  ID</th><th>Name              </th><th>Dataset ID                          </th><th>Description  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   0</td><td>LangChain Docs Q&amp;A</td><td>452ccafc-18e1-4314-885b-edd735f17b9d</td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
       "\n",
       "The environment provides the documents and the retriever information.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model&#x27;s response relative to the retrieved documents (if any).              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Registry(environments=[RetrievalEnvironment(id=0, name='LangChain Docs Q&A', dataset_id='452ccafc-18e1-4314-885b-edd735f17b9d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x12f5f7d80>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x12f5f7e20>, 'hyde': <function _chroma_hyde_retriever_factory at 0x12f5f7ec0>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x10fda4540>})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671282f8-c455-4390-b018-e53bbd833093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>ID                    </td><td>0                                   </td></tr>\n",
       "<tr><td>Name                  </td><td>LangChain Docs Q&amp;A                  </td></tr>\n",
       "<tr><td>Dataset ID            </td><td>452ccafc-18e1-4314-885b-edd735f17b9d</td></tr>\n",
       "<tr><td>Description           </td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
       "\n",
       "The environment provides th...                                     </td></tr>\n",
       "<tr><td>Retriever Factories   </td><td>basic, parent-doc, hyde             </td></tr>\n",
       "<tr><td>Architecture Factories</td><td>conversational-retrieval-qa         </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "RetrievalEnvironment(id=0, name='LangChain Docs Q&A', dataset_id='452ccafc-18e1-4314-885b-edd735f17b9d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x12f5f7d80>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x12f5f7e20>, 'hyde': <function _chroma_hyde_retriever_factory at 0x12f5f7ec0>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x10fda4540>})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_docs = registry[0]\n",
    "langchain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset LangChain Docs Q&A already exists. Skipping.\n",
      "You can access the dataset at http://localhost/o/00000000-0000-0000-0000-000000000000/datasets/1e4bf58b-1a61-44fb-bb84-4c5c0e2b4b5b.\n"
     ]
    }
   ],
   "source": [
    "clone_public_dataset(langchain_docs.dataset_id, dataset_name=langchain_docs.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58247f5-b9bd-4cc5-9632-78bc21bb10b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n",
    "\n",
    "retriever_factory = langchain_docs.retriever_factories[\"basic\"]\n",
    "# Indexes the documents with the specified embeddings\n",
    "# Note that this does not apply any chunking to the docs,\n",
    "# which means the documents can be of arbitrary length\n",
    "retriever = retriever_factory(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d2e139-2653-4f7b-944b-91ef52f43d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factory for creating a conversational retrieval QA chain\n",
    "\n",
    "chain_factory = langchain_docs.architecture_factories[\"conversational-retrieval-qa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f9be718-64f0-4706-9527-240a1cdb3ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" LCEL (LangChain Expression Language) is a declarative way to easily compose chains together in Langchain. Here's a brief 80 word summary:\\n\\nLCEL lets you build chains for NLP tasks like Question Answering by composing together Runnables - reusable building blocks. It supports streaming, parallelism, retries, and more. Chains built with LCEL integrate seamlessly with LangSmith for observability and LangServe for production deployment. LCEL makes it easy to go from prototype to production with no code change. Key features include performance optimizations, access to intermediate results, and input/output validation via schemas. [0][1][2][3]\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "\n",
    "# Example\n",
    "llm = ChatAnthropic(model=\"claude-2\", temperature=1)\n",
    "\n",
    "chain_factory(retriever, llm=llm).invoke({\"question\": \"what's lcel?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Let's evaluate a retriever now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "513042fe-2878-44f8-ae84-05b9d521c1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from langchain_benchmarks.rag import RAG_EVALUATION\n",
    "from langsmith.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bedd9d1-fc06-4066-9f89-b874ae818d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab7514e-a6ef-4c21-b90f-d9cbefcf5af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-essential-wood-50' at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/projects/p/77aefb67-1c66-45e0-a508-cea0faaf30c1?eval=true\n",
      "\n",
      "View all tests for Dataset LangChain Docs Q&A at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/datasets/1e4bf58b-1a61-44fb-bb84-4c5c0e2b4b5b\n",
      "[------------------------------------------------->] 86/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Eval quantiles:\n",
      "        embedding_cosine_distance  faithfulness  score_string:accuracy error  \\\n",
      "count                   86.000000     86.000000              86.000000     0   \n",
      "unique                        NaN           NaN                    NaN     0   \n",
      "top                           NaN           NaN                    NaN   NaN   \n",
      "freq                          NaN           NaN                    NaN   NaN   \n",
      "mean                     0.127803      0.769767               0.620930   NaN   \n",
      "std                      0.059222      0.302954               0.327958   NaN   \n",
      "min                      0.036791      0.100000               0.100000   NaN   \n",
      "25%                      0.082071      0.500000               0.500000   NaN   \n",
      "50%                      0.116762      1.000000               0.700000   NaN   \n",
      "75%                      0.157451      1.000000               1.000000   NaN   \n",
      "max                      0.308346      1.000000               1.000000   NaN   \n",
      "\n",
      "        execution_time  \n",
      "count        86.000000  \n",
      "unique             NaN  \n",
      "top                NaN  \n",
      "freq               NaN  \n",
      "mean         19.343951  \n",
      "std           5.240861  \n",
      "min           5.946557  \n",
      "25%          15.802171  \n",
      "50%          19.639004  \n",
      "75%          22.089945  \n",
      "max          34.601682  \n"
     ]
    }
   ],
   "source": [
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, retriever, llm=llm),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e86578d5-be5c-4bcd-9dcb-35280eeed3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>score_string:accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.127803</td>\n",
       "      <td>0.769767</td>\n",
       "      <td>0.620930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.343951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.059222</td>\n",
       "      <td>0.302954</td>\n",
       "      <td>0.327958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.240861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.036791</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.946557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082071</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.802171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.116762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.639004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.157451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.089945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.308346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.601682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        embedding_cosine_distance  faithfulness  score_string:accuracy error  \\\n",
       "count                   86.000000     86.000000              86.000000     0   \n",
       "unique                        NaN           NaN                    NaN     0   \n",
       "top                           NaN           NaN                    NaN   NaN   \n",
       "freq                          NaN           NaN                    NaN   NaN   \n",
       "mean                     0.127803      0.769767               0.620930   NaN   \n",
       "std                      0.059222      0.302954               0.327958   NaN   \n",
       "min                      0.036791      0.100000               0.100000   NaN   \n",
       "25%                      0.082071      0.500000               0.500000   NaN   \n",
       "50%                      0.116762      1.000000               0.700000   NaN   \n",
       "75%                      0.157451      1.000000               1.000000   NaN   \n",
       "max                      0.308346      1.000000               1.000000   NaN   \n",
       "\n",
       "        execution_time  \n",
       "count        86.000000  \n",
       "unique             NaN  \n",
       "top                NaN  \n",
       "freq               NaN  \n",
       "mean         19.343951  \n",
       "std           5.240861  \n",
       "min           5.946557  \n",
       "25%          15.802171  \n",
       "50%          19.639004  \n",
       "75%          22.089945  \n",
       "max          34.601682  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee992f87-4137-49b1-a1f1-0cc7be0e32d8",
   "metadata": {},
   "source": [
    "# Comparing with other indexing strategies\n",
    "\n",
    "The index used above retrieves the raw documents based on a single vector per document. It doesn't perform any additional chunking. You can try changing the chunking parameters when generating the index.\n",
    "\n",
    "## Customizing Chunking\n",
    "\n",
    "The simplest change you can make to the index is configure how you split the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e72030d4-c201-44b8-85cd-903afa313f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def transform_docs(docs):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=200)\n",
    "    yield from splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Used for the cache\n",
    "transformation_name = \"recursive-text-cs4k-ol200\"\n",
    "\n",
    "retriever_factory = langchain_docs.retriever_factories[\"basic\"]\n",
    "\n",
    "chunked_retriever = retriever_factory(\n",
    "    embeddings,\n",
    "    transform_docs=transform_docs,\n",
    "    transformation_name=transformation_name,\n",
    "    search_kwargs={\"k\": 4},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d74f12f9-1ba6-4bf7-a850-4073fb0994f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-spotless-rhythm-97' at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/projects/p/0fe51c4e-b79a-4edd-8443-0fecf8bc220e?eval=true\n",
      "\n",
      "View all tests for Dataset LangChain Docs Q&A at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/datasets/1e4bf58b-1a61-44fb-bb84-4c5c0e2b4b5b\n",
      "[------------------------------------------------->] 86/86\n",
      " Eval quantiles:\n",
      "        embedding_cosine_distance  score_string:accuracy  faithfulness error  \\\n",
      "count                   86.000000              86.000000     86.000000     0   \n",
      "unique                        NaN                    NaN           NaN     0   \n",
      "top                           NaN                    NaN           NaN   NaN   \n",
      "freq                          NaN                    NaN           NaN   NaN   \n",
      "mean                     0.131206               0.574419      0.755814   NaN   \n",
      "std                      0.057896               0.322558      0.319413   NaN   \n",
      "min                      0.035323               0.100000      0.100000   NaN   \n",
      "25%                      0.089841               0.300000      0.500000   NaN   \n",
      "50%                      0.119418               0.600000      1.000000   NaN   \n",
      "75%                      0.158104               0.850000      1.000000   NaN   \n",
      "max                      0.312070               1.000000      1.000000   NaN   \n",
      "\n",
      "        execution_time  \n",
      "count        86.000000  \n",
      "unique             NaN  \n",
      "top                NaN  \n",
      "freq               NaN  \n",
      "mean         16.795995  \n",
      "std           6.063518  \n",
      "min           4.930493  \n",
      "25%          13.534636  \n",
      "50%          16.058093  \n",
      "75%          18.820127  \n",
      "max          46.262452  \n"
     ]
    }
   ],
   "source": [
    "chunked_results = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, retriever, llm=llm),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6d825f1-9a91-429d-bf3e-a9b9c2785a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>score_string:accuracy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.131206</td>\n",
       "      <td>0.574419</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.795995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.057896</td>\n",
       "      <td>0.322558</td>\n",
       "      <td>0.319413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.063518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.035323</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.930493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.089841</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.534636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.119418</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.058093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.158104</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.820127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.312070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.262452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        embedding_cosine_distance  score_string:accuracy  faithfulness error  \\\n",
       "count                   86.000000              86.000000     86.000000     0   \n",
       "unique                        NaN                    NaN           NaN     0   \n",
       "top                           NaN                    NaN           NaN   NaN   \n",
       "freq                          NaN                    NaN           NaN   NaN   \n",
       "mean                     0.131206               0.574419      0.755814   NaN   \n",
       "std                      0.057896               0.322558      0.319413   NaN   \n",
       "min                      0.035323               0.100000      0.100000   NaN   \n",
       "25%                      0.089841               0.300000      0.500000   NaN   \n",
       "50%                      0.119418               0.600000      1.000000   NaN   \n",
       "75%                      0.158104               0.850000      1.000000   NaN   \n",
       "max                      0.312070               1.000000      1.000000   NaN   \n",
       "\n",
       "        execution_time  \n",
       "count        86.000000  \n",
       "unique             NaN  \n",
       "top                NaN  \n",
       "freq               NaN  \n",
       "mean         16.795995  \n",
       "std           6.063518  \n",
       "min           4.930493  \n",
       "25%          13.534636  \n",
       "50%          16.058093  \n",
       "75%          18.820127  \n",
       "max          46.262452  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_results.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a62ec-9a9c-4d7a-ab90-97020d855ee7",
   "metadata": {},
   "source": [
    "## Parent Document Retriever\n",
    "\n",
    "This indexing technique chunks documents and generates 1 vector per chunk.\n",
    "At retrieval time, the K \"most similar\" chunks are fetched, then the full parent documents are returned for the LLM to reason over.\n",
    "\n",
    "This ensures the chunk is surfaced in its full natural context. It also can potentially improve the initial retrieval quality since the similarity scores are scoped to individual chunks.\n",
    "\n",
    "Let's see if this technique is effective in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398f5e3-b7fe-4693-bcc0-c6c6f75c8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_factory = langchain_docs.retriever_factories[\"parent-doc\"]\n",
    "\n",
    "# Indexes the documents with the specified embeddings\n",
    "parent_doc_retriever = retriever_factory(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f4b5d-143a-44ce-95f4-d0b5782ada74",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_doc_test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, parent_doc_retriever, llm=llm),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef0410-47ec-4830-9b75-621eb85240ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_doc_test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b27dd0-f0df-4551-a972-1a6c0df5ffb9",
   "metadata": {},
   "source": [
    "## HyDE\n",
    "\n",
    "HyDE (Hypothetical document embeddings) refers to the technique of using an LLM\n",
    "to generate example queries that my be used to retrieve a doc. By doing so, the resulting embeddings are automatically \"more aligned\" with the embeddings generated from the query. This comes with an additional indexing cost, since each document requires an additoinal call to an LLM while indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92d2c2-f410-43cc-9c9f-abc22ef48353",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_factory = langchain_docs.retriever_factories[\"hyde\"]\n",
    "\n",
    "retriever = retriever_factory(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2179cf29-2d75-4a04-bbb5-b8f22028fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, retriever),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a04f21-0308-4b00-a6f1-694d98ba7109",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8af309-d0c4-4562-a5f0-30ca9f9fd861",
   "metadata": {},
   "source": [
    "# Comparing Embeddings\n",
    "\n",
    "We've been using off-the-shelf GTE-Base embeddings so far to retrieve the docs, but\n",
    "you may get better results with other embeddings. You could even try fine-tuning embedddings on your own documentation and evaluating here.\n",
    "\n",
    "Let's compare our results so far to OpenAI's embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b2395-c07e-4eae-bb21-afdda3961cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5edab-9a3a-4864-b69f-69bc1c9e7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_retriever = langchain_docs.retriever_factories[\"basic\"](openai_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757c411-aaa5-42ad-824c-7c0b5b942e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embeddings_test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, openai_retriever),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae7cbe-a8eb-4b40-aeae-f9c7f4bf335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embeddings_test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef164b9-7124-4907-b2b4-0595bf3b3441",
   "metadata": {},
   "source": [
    "## Comparing Models\n",
    "\n",
    "We used Anthropic's Claude-2 model in our previous tests, but lets try with some other models.\n",
    "\n",
    "You can swap in any LangChain LLM within the response generator below.\n",
    "We'll try a long-context llama 2 model first (using Ollama)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "402c86c7-9754-4527-a1a9-a89beba437b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "# A llama2-based model with 128k context\n",
    "# (in theory) In practice, we will see how well\n",
    "# it actually leverages that context.\n",
    "ollama = ChatOllama(model=\"yarn-llama2:7b-128k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc7dff86-2b93-490a-81ab-72e757e8f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll go back to the GTE embeddings for now\n",
    "\n",
    "retriever_factory = langchain_docs.retriever_factories[\"basic\"]\n",
    "retriever = retriever_factory(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaa47085-e383-4cc5-9018-5491700c6f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-complicated-motion-26' at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/projects/p/10089cd0-a4dc-45e1-8c6d-66143324944c?eval=true\n",
      "\n",
      "View all tests for Dataset LangChain Docs Q&A at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/datasets/1e4bf58b-1a61-44fb-bb84-4c5c0e2b4b5b\n",
      "[>                                                 ] 0/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 9ee18a2e-34a9-4578-8afe-40d98ade8f7b with inputs {'question': 'how do i initialize OpenAIAnthropicVectorStore?'}\n",
      "Error Type: ValueError, Message: Ollama call failed with status code 500. Details: llama runner process has terminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>                                                 ] 1/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "Chain failed for example c737a33a-fb32-4b85-92cd-1b204c698231 with inputs {'question': 'whats the difference between run house and click house'}\n",
      "Error Type: ValueError, Message: Ollama call failed with status code 500. Details: llama runner process has terminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>                                                 ] 2/86"
     ]
    }
   ],
   "source": [
    "ollama_test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, llm=ollama, retriever=retriever),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98edcf42-a405-400b-882e-04de2559359c",
   "metadata": {},
   "source": [
    "## Changing the prompt in the response generator\n",
    "\n",
    "The default prompt was tested primariily on OpenAI's gpt-3.5 model. When switching models, you may get better results if you modify the prompt. Let's try a simple one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3b36f-68aa-4005-9bb2-de228491ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64caac6f-888d-432c-9329-5c4b97ad859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"wfh/rag-simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e6762-1e50-4eef-833a-a4a2bf8883ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = prompt | ChatAnthropic(model=\"claude-2\", temperature=1) | StrOutputParser()\n",
    "new_chain = chain_factory(response_synthesizer=generator, retriever=openai_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96886de0-a653-4875-a68f-5a11efcb200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_simple_prompt_test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(\n",
    "        chain_factory, response_synthesizer=generator, retriever=retriever\n",
    "    ),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffaf28-902e-4466-b3b9-25441d45585d",
   "metadata": {},
   "source": [
    "## Testing Agents\n",
    "\n",
    "Agents use an LLM to decide actions and generate responses. There are two obvious ways they could potentially succeed where the approaches above fail:\n",
    "- The above chains do not \"rephrase\" the user query. It could be that the rephrased question will result in more relevant documents.\n",
    "- The above chains must respond based on a single retrieval step. Agents can iteratively query the retriever or subdivide the query into different parts to synthesize at the end. Our dataset has a number of questions that require information from different documents - if the\n",
    "\n",
    "Let's evaluate to see whether the \"plausible\" statements above are worth the tradeoffs. We will use the basic retriever as a tool for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c31c19c4-f8d6-41b3-9389-e89abd4b5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.schema.messages import AIMessage, HumanMessage\n",
    "from langchain.tools import tool\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "# This is used to tell the model how to best use the retriever.\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query, callbacks=None):\n",
    "    \"\"\"Search the LangChain docs with the retriever.\"\"\"\n",
    "    return retriever.get_relevant_documents(query, callbacks=callbacks)\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0)\n",
    "assistant_system_message = \"\"\"You are a helpful assistant tasked with answering technical questions about LangChain. \\\n",
    "Use tools (only if necessary) to best answer the users questions. Do not make up information if you cannot find the answer using your tools.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", assistant_system_message),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]):\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: _format_chat_history(x[\"chat_history\"]),\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_functions(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "class AgentInput(BaseModel):\n",
    "    input: str\n",
    "    chat_history: List[Tuple[str, str]] = Field(..., extra={\"widget\": {\"type\": \"chat\"}})\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False).with_types(\n",
    "    input_type=AgentInput\n",
    ")\n",
    "\n",
    "\n",
    "class ChainInput(BaseModel):\n",
    "    question: str\n",
    "\n",
    "\n",
    "def mapper(input: dict):\n",
    "    return {\"input\": input[\"question\"], \"chat_history\": []}\n",
    "\n",
    "\n",
    "agent_executor = (mapper | agent_executor | (lambda x: x[\"output\"])).with_types(\n",
    "    input_type=ChainInput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a1c09c2-a983-450b-a531-c6871a9b27ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-mealy-lip-56' at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/projects/p/fc7df61c-9062-40d4-a823-5051cf3f551c?eval=true\n",
      "\n",
      "View all tests for Dataset LangChain Docs Q&A at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/datasets/1e4bf58b-1a61-44fb-bb84-4c5c0e2b4b5b\n",
      "[--------->                                        ] 18/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 1f97ba11-f475-4974-b179-3be47f5882ec with inputs {'question': 'How do i run llama 2 in langchain'}\n",
      "Error Type: InvalidRequestError, Message: This model's maximum context length is 16385 tokens. However, your messages resulted in 19672 tokens (19627 in the messages, 45 in the functions). Please reduce the length of the messages or functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------->            ] 65/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example cb004261-4831-4477-a4f8-3d7b69919ff6 with inputs {'question': 'Show me an example using Weaviate, but customizing the VectorStoreRetriever to return the top 10 k nearest neighbors. '}\n",
      "Error Type: InvalidRequestError, Message: This model's maximum context length is 16385 tokens. However, your messages resulted in 20974 tokens (20929 in the messages, 45 in the functions). Please reduce the length of the messages or functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 86/86\n",
      " Eval quantiles:\n",
      "        embedding_cosine_distance  faithfulness  score_string:accuracy  \\\n",
      "count                   84.000000     81.000000              84.000000   \n",
      "unique                        NaN           NaN                    NaN   \n",
      "top                           NaN           NaN                    NaN   \n",
      "freq                          NaN           NaN                    NaN   \n",
      "mean                     0.122338      0.696296               0.521429   \n",
      "std                      0.063324      0.312027               0.329685   \n",
      "min                      0.028011      0.100000               0.100000   \n",
      "25%                      0.077464      0.500000               0.100000   \n",
      "50%                      0.109392      0.700000               0.500000   \n",
      "75%                      0.159934      1.000000               0.700000   \n",
      "max                      0.293347      1.000000               1.000000   \n",
      "\n",
      "                                                    error  execution_time  \n",
      "count                                                   2       86.000000  \n",
      "unique                                                  2             NaN  \n",
      "top     This model's maximum context length is 16385 t...             NaN  \n",
      "freq                                                    1             NaN  \n",
      "mean                                                  NaN        8.718085  \n",
      "std                                                   NaN        3.768497  \n",
      "min                                                   NaN        1.194332  \n",
      "25%                                                   NaN        6.155838  \n",
      "50%                                                   NaN        8.360487  \n",
      "75%                                                   NaN       11.272704  \n",
      "max                                                   NaN       20.600593  \n"
     ]
    }
   ],
   "source": [
    "oai_functions_test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=agent_executor,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffd740-fde1-479d-b84c-7dd8f65716a6",
   "metadata": {},
   "source": [
    "## Assistant\n",
    "\n",
    "OpenAI provides a hosted agent service through their Assistants API. \n",
    "\n",
    "You can connect your LangChain retriever to an OpenAI's Assistant API and evaluate its performance. Let's test below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de4d42b-e34a-4980-97eb-9b2c78a24089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.tools import tool\n",
    "from langchain_experimental.openai_assistant import OpenAIAssistantRunnable\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query, callbacks=None) -> str:\n",
    "    \"\"\"Search the LangChain docs with the retriever.\"\"\"\n",
    "    docs = retriever.get_relevant_documents(query, callbacks=callbacks)\n",
    "    return json.dumps([doc.dict() for doc in docs])\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "agent = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain docs assistant\",\n",
    "    instructions=\"You are a helpful assistant tasked with answering technical questions about LangChain.\",\n",
    "    tools=tools,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    as_agent=True,\n",
    ")\n",
    "\n",
    "\n",
    "assistant_exector = (\n",
    "    (lambda x: {\"content\": x[\"question\"]})\n",
    "    | AgentExecutor(agent=agent, tools=tools)\n",
    "    | (lambda x: x[\"output\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd6baea1-ac90-43aa-a21c-98aa5ca23732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-long-night-86' at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/projects/p/da7b7f81-926c-4155-95fe-0c9a91b7983b?eval=true\n",
      "\n",
      "View all tests for Dataset LangChain Docs Q&A at:\n",
      "http://localhost/o/00000000-0000-0000-0000-000000000000/datasets/1e4bf58b-1a61-44fb-bb84-4c5c0e2b4b5b\n",
      "[>                                                 ] 0/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>                                                 ] 1/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------------------->                    ] 52/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example d42a702e-3a92-4cb6-9148-8fa9a5f6c062 with inputs {'question': 'How do I load Youtube transcripts and CSV documents?'}\n",
      "Error Type: BadRequestError, Message: Error code: 400 - {'error': {'message': \"Expected tool outputs for call_ids ['call_xOTr7Y2mMgAvBngL55HOluqO', 'call_lSnkgQ94fb7wEMyP9LupkNEn'], got ['call_lSnkgQ94fb7wEMyP9LupkNEn']\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 86/86\n",
      " Eval quantiles:\n",
      "        score_string:accuracy  faithfulness  embedding_cosine_distance  \\\n",
      "count                     0.0           0.0                  85.000000   \n",
      "unique                    NaN           NaN                        NaN   \n",
      "top                       NaN           NaN                        NaN   \n",
      "freq                      NaN           NaN                        NaN   \n",
      "mean                      NaN           NaN                   0.129928   \n",
      "std                       NaN           NaN                   0.061485   \n",
      "min                       NaN           NaN                   0.028841   \n",
      "25%                       NaN           NaN                   0.083430   \n",
      "50%                       NaN           NaN                   0.118423   \n",
      "75%                       NaN           NaN                   0.155580   \n",
      "max                       NaN           NaN                   0.343805   \n",
      "\n",
      "                                                    error  execution_time  \n",
      "count                                                   1       86.000000  \n",
      "unique                                                  1             NaN  \n",
      "top     Error code: 400 - {'error': {'message': \"Expec...             NaN  \n",
      "freq                                                    1             NaN  \n",
      "mean                                                  NaN       28.175951  \n",
      "std                                                   NaN       10.704861  \n",
      "min                                                   NaN        6.088222  \n",
      "25%                                                   NaN       22.164567  \n",
      "50%                                                   NaN       26.051888  \n",
      "75%                                                   NaN       34.683894  \n",
      "max                                                   NaN       58.611196  \n"
     ]
    }
   ],
   "source": [
    "assistant_test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=assistant_exector,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5ac5fad-0a74-4403-a917-7145be6d7d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_string:accuracy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Error code: 400 - {'error': {'message': \"Expec...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.175951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.704861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.088222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.164567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.051888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.155580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.683894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.343805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.611196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score_string:accuracy  faithfulness  embedding_cosine_distance  \\\n",
       "count                     0.0           0.0                  85.000000   \n",
       "unique                    NaN           NaN                        NaN   \n",
       "top                       NaN           NaN                        NaN   \n",
       "freq                      NaN           NaN                        NaN   \n",
       "mean                      NaN           NaN                   0.129928   \n",
       "std                       NaN           NaN                   0.061485   \n",
       "min                       NaN           NaN                   0.028841   \n",
       "25%                       NaN           NaN                   0.083430   \n",
       "50%                       NaN           NaN                   0.118423   \n",
       "75%                       NaN           NaN                   0.155580   \n",
       "max                       NaN           NaN                   0.343805   \n",
       "\n",
       "                                                    error  execution_time  \n",
       "count                                                   1       86.000000  \n",
       "unique                                                  1             NaN  \n",
       "top     Error code: 400 - {'error': {'message': \"Expec...             NaN  \n",
       "freq                                                    1             NaN  \n",
       "mean                                                  NaN       28.175951  \n",
       "std                                                   NaN       10.704861  \n",
       "min                                                   NaN        6.088222  \n",
       "25%                                                   NaN       22.164567  \n",
       "50%                                                   NaN       26.051888  \n",
       "75%                                                   NaN       34.683894  \n",
       "max                                                   NaN       58.611196  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04b3e4-b5df-4075-9089-8aa10ef63348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
